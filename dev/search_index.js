var documenterSearchIndex = {"docs":
[{"location":"#LazyArrays.jl","page":"Home","title":"LazyArrays.jl","text":"","category":"section"},{"location":"#LazyArrays.LazyArrays","page":"Home","title":"LazyArrays.LazyArrays","text":"LazyArrays.jl\n\n(Image: Dev) (Image: Build Status) (Image: codecov) (Image: pkgeval)\n\nLazy arrays and linear algebra in Julia\n\nThis package supports lazy analogues of array operations like vcat, hcat, and multiplication. This helps with the implementation of matrix-free methods for iterative solvers.\n\nThe package has been designed with high-performance in mind, so should outperform the non-lazy analogues from Base for many operations like copyto! and broadcasting. Some operations will be inherently slower due to extra computation, like getindex. Please file an issue for any examples that are significantly slower than their the analogue in Base.\n\nLazy operations\n\nTo construct a lazy representation of a function call f(x,y,z...), use the command applied(f, x, y, z...). This will return an unmaterialized object typically of type Applied that represents the operation. To realize that object, call materialize, which  will typically be equivalent to calling f(x,y,z...). A macro @~ is available as a shorthand:\n\njulia> using LazyArrays, LinearAlgebra\n\njulia> applied(exp, 1)\nApplied(exp,1)\n\njulia> materialize(applied(exp, 1))\n2.718281828459045\n\njulia> materialize(@~ exp(1))\n2.718281828459045\n\njulia> exp(1)\n2.718281828459045\n\nNote that @~ causes sub-expressions to be wrapped in an applied call, not just the top-level expression. This can lead to MethodErrors when lazy application of sub-expressions is not yet implemented. For example,\n\njulia> @~ Vector(1:10) .* ones(10)'\nERROR: MethodError: ...\n\njulia> A = Vector(1:10); B = ones(10); (@~ sum(A .* B')) |> materialize\n550.0\n\nThe benefit of lazy operations is that they can be materialized in-place,  possible using simplifications. For example, it is possible to  do BLAS-like Matrix-Vector operations of the form α*A*x + β*y as  implemented in BLAS.gemv! using a lazy applied object:\n\njulia> A = randn(5,5); b = randn(5); c = randn(5); d = similar(c);\n\njulia> d .= @~ 2.0 * A * b + 3.0 * c # Calls gemv!\n5-element Vector{Float64}:\n -2.5366335879717514\n -5.305097174484744  \n -9.818431932350942  \n  2.421562605495651  \n  0.26792916096572983\n\njulia> 2*(A*b) + 3c\n5-element Vector{Float64}:\n -2.5366335879717514\n -5.305097174484744  \n -9.818431932350942  \n  2.421562605495651  \n  0.26792916096572983\n\njulia> function mymul(A, b, c, d) # need to put in function for benchmarking\n           d .= @~ 2.0 * A * b + 3.0 * c\n       end\nmymul (generic function with 1 method)\n\njulia> using BenchmarkTools\n\njulia> @btime mymul(A, b, c, d) # calls gemv!\n  77.444 ns (0 allocations: 0 bytes)\n5-element Vector{Float64}:\n -2.5366335879717514\n -5.305097174484744  \n -9.818431932350942  \n  2.421562605495651  \n  0.26792916096572983\n\njulia> @btime 2*(A*b) + 3c; # does not call gemv!\n  241.659 ns (4 allocations: 512 bytes)\n\nThis also works for inverses, which lower to BLAS calls whenever possible:\n\njulia> A = randn(5,5); b = randn(5); c = similar(b);\n\njulia> c .= @~ A \\ b\n5-element Vector{Float64}:\n -2.5366335879717514\n -5.305097174484744  \n -9.818431932350942  \n  2.421562605495651  \n  0.26792916096572983\n\nLazy arrays\n\nOften we want lazy realizations of matrices, which are supported via ApplyArray. For example, the following creates a lazy matrix exponential:\n\njulia> E = ApplyArray(exp, [1 2; 3 4])\nexp(2×2 Matrix{Int64}):\n  51.969   74.7366\n 112.105  164.074 \n\nA lazy matrix exponential is useful for, say, in-place matrix-exponential*vector:\n\njulia> b = Vector{Float64}(undef, 2); b .= @~ E*[4,4]\n2-element Vector{Float64}:\n  506.8220830628333\n 1104.7145995988594\n\nWhile this works, it is not actually optimised (yet). \n\nOther options do have special implementations that make them fast. We now give some examples. \n\nConcatenation\n\nLazy vcat and hcat allow for representing the concatenation of vectors without actually allocating memory, and support a fast copyto!  for allocation-free population of a vector.\n\njulia> using BenchmarkTools\n\njulia> A = ApplyArray(vcat,1:5,2:3) # allocation-free\nvcat(5-element UnitRange{Int64}, 2-element UnitRange{Int64}):\n 1\n 2\n 3\n 4\n 5\n 2\n 3\n\njulia> Vector(A) == vcat(1:5, 2:3)\ntrue\n\njulia> b = Array{Int}(undef, length(A)); @btime copyto!(b, A);\n  26.670 ns (0 allocations: 0 bytes)\n\njulia> @btime vcat(1:5, 2:3); # takes twice as long due to memory creation\n  43.336 ns (1 allocation: 144 bytes)\n\nSimilar is the lazy analogue of hcat:\n\njulia> A = ApplyArray(hcat, 1:3, randn(3,10))\nhcat(3-element UnitRange{Int64}, 3×10 Matrix{Float64}):\n 1.0   1.16561    0.224871  -1.36416   -0.30675    0.103714    0.590141   0.982382  -1.50045    0.323747  -1.28173  \n 2.0   1.04648    1.35506   -0.147157   0.995657  -0.616321   -0.128672  -0.671445  -0.563587  -0.268389  -1.71004  \n 3.0  -0.433093  -0.325207  -1.38496   -0.391113  -0.0568739  -1.55796   -1.00747    0.473686  -1.2113     0.0119156\n\njulia> Matrix(A) == hcat(A.args...)\ntrue\n\njulia> B = Array{Float64}(undef, size(A)...); @btime copyto!(B, A);\n  109.625 ns (1 allocation: 32 bytes)\n\njulia> @btime hcat(A.args...); # takes twice as long due to memory creation\n  274.620 ns (6 allocations: 560 bytes)\n\nKronecker products\n\nWe can represent Kronecker products of arrays without constructing the full array:\n\njulia> A = randn(2,2); B = randn(3,3);\n\njulia> K = ApplyArray(kron,A,B)\nkron(2×2 Matrix{Float64}, 3×3 Matrix{Float64}):\n -1.08736   -0.19547   -0.132824   1.60531    0.288579    0.196093 \n  0.353898   0.445557  -0.257776  -0.522472  -0.657791    0.380564 \n -0.723707   0.911737  -0.710378   1.06843   -1.34603     1.04876  \n  1.40606    0.252761   0.171754  -0.403809  -0.0725908  -0.0493262\n -0.457623  -0.576146   0.333329   0.131426   0.165464   -0.0957293\n  0.935821  -1.17896    0.918584  -0.26876    0.338588   -0.26381  \n\njulia> C = Matrix{Float64}(undef, 6, 6); @btime copyto!(C, K);\n  61.528 ns (0 allocations: 0 bytes)\n\njulia> C == kron(A,B)\ntrue\n\nBroadcasting\n\nBase includes a lazy broadcast object called Broadcasting, but this is not a subtype of AbstractArray. Here we have BroadcastArray which replicates the functionality of Broadcasting while supporting the array interface.\n\njulia> A = randn(6,6);\n\njulia> B = BroadcastArray(exp, A);\n\njulia> Matrix(B) == exp.(A)\ntrue\n\njulia> B = BroadcastArray(+, A, 2);\n\njulia> B == A .+ 2\ntrue\n\nSuch arrays can also be created using the macro @~ which acts on ordinary  broadcasting expressions combined with LazyArray:\n\njulia> C = rand(1000)';\n\njulia> D = LazyArray(@~ exp.(C))\n\njulia> E = LazyArray(@~ @. 2 + log(C))\n\njulia> @btime sum(LazyArray(@~ C .* C'); dims=1) # without `@~`, 1.438 ms (5 allocations: 7.64 MiB)\n  74.425 μs (7 allocations: 8.08 KiB)\n\n\n\n\n\n","category":"module"},{"location":"#LazyArrays.Applied","page":"Home","title":"LazyArrays.Applied","text":"Applied(f, A...)\n\nis a lazy version of f(A...) that can be manipulated or materialized in a non-standard manner.\n\n\n\n\n\n","category":"type"},{"location":"#LazyArrays.LazyArray","page":"Home","title":"LazyArrays.LazyArray","text":"LazyArray(x::Applied) :: ApplyArray\nLazyArray(x::Broadcasted) :: BroadcastArray\n\nWrap a lazy object that wraps a computation producing an array to an array.\n\n\n\n\n\n","category":"type"},{"location":"#LazyArrays.cache-Union{Tuple{MT}, Tuple{Type{MT}, AbstractArray}} where MT<:AbstractArray","page":"Home","title":"LazyArrays.cache","text":"cache(array::AbstractArray)\n\nCaches the entries of an array.\n\n\n\n\n\n","category":"method"},{"location":"#LazyArrays.@~-Tuple{Any}","page":"Home","title":"LazyArrays.@~","text":"@~ expr\n\nMacro for creating a Broadcasted or Applied object.  Regular calls like f(args...) inside expr are replaced with applied(f, args...). Dotted-calls like f(args...) inside expr are replaced with broadcasted.(f, args...).  Use LazyArray(@~ expr) if you need an array-based interface.\n\njulia> @~ A .+ B ./ 2\n\njulia> @~ @. A + B / 2\n\njulia> @~ A * B + C\n\n\n\n\n\n","category":"macro"},{"location":"internals/#Internals","page":"Internals","title":"Internals","text":"","category":"section"},{"location":"internals/#LazyArrays.AbstractArrayApplyStyle","page":"Internals","title":"LazyArrays.AbstractArrayApplyStyle","text":"AbstractArrayApplyStyle\n\nis an abstract type whose subtypes indicate how a lazy function is materialized, where the result is an AbstractArray.\n\n\n\n\n\n","category":"type"},{"location":"internals/#LazyArrays.Add-Tuple","page":"Internals","title":"LazyArrays.Add","text":"Add(A1, A2, …, AN)\n\nA lazy representation of A1 + A2 + … + AN; i.e., a shorthand for applied(+, A1, A2, …, AN).\n\n\n\n\n\n","category":"method"},{"location":"internals/#LazyArrays.ApplyStyle","page":"Internals","title":"LazyArrays.ApplyStyle","text":"ApplyStyle\n\nis an abstract type whose subtypes indicate how a lazy function is materialized. The default is DefaultApplyStyle which indicates that applied(f, A...) is materialized as f(A...).\n\n\n\n\n\n","category":"type"},{"location":"internals/#LazyArrays.BroadcastLayout","page":"Internals","title":"LazyArrays.BroadcastLayout","text":"BroadcastLayout{F}()\n\nis returned by MemoryLayout(A) if a matrix A is a BroadcastArray. F is the typeof function that broadcast operation is applied.\n\n\n\n\n\n","category":"type"},{"location":"internals/#LazyArrays.DefaultApplyStyle","page":"Internals","title":"LazyArrays.DefaultApplyStyle","text":"DefaultApplyStyle\n\nindicate that a lazy function application applied(f, A...) is materialized as f(A...).\n\n\n\n\n\n","category":"type"},{"location":"internals/#LazyArrays.DefaultArrayApplyStyle","page":"Internals","title":"LazyArrays.DefaultArrayApplyStyle","text":"DefaultArrayApplyStyle\n\nis like DefaultApplyStyle but indicates that the result is an array.\n\n\n\n\n\n","category":"type"},{"location":"internals/#LazyArrays.MulAddStyle","page":"Internals","title":"LazyArrays.MulAddStyle","text":"MulAddStyle\n\nindicates that an Applied object should be materialised via ArrayLayouts.MulAdd.\n\n\n\n\n\n","category":"type"},{"location":"internals/#LazyArrays.MulStyle","page":"Internals","title":"LazyArrays.MulStyle","text":"MulStyle\n\nindicates that an Applied object should be materialized via Mul.\n\n\n\n\n\n","category":"type"},{"location":"internals/#LazyArrays.PaddedColumns","page":"Internals","title":"LazyArrays.PaddedColumns","text":"PaddedColumns{L}()\n\nrepresents a vector or matrix with layout L() whose columns have been padded with zeros below, i.e., a lazy version of [A; Zeros(...)].\n\n\n\n\n\n","category":"type"},{"location":"internals/#LazyArrays.PaddedLayout","page":"Internals","title":"LazyArrays.PaddedLayout","text":"PaddedLayout{L}()\n\nrepresents a matrix whose rows and columns have been padded.\n\n\n\n\n\n","category":"type"},{"location":"internals/#LazyArrays.PaddedRows","page":"Internals","title":"LazyArrays.PaddedRows","text":"PaddedRows{L}()\n\nrepresents a matrix with layout L() whose rows have been padded with zeros below, i.e., a lazy version of [A Zeros(...)].\n\n\n\n\n\n","category":"type"},{"location":"internals/#LazyArrays.is_dotcall-Tuple{Any}","page":"Internals","title":"LazyArrays.is_dotcall","text":"Check if ex is a dot-call expression like f.(x, y, z) or x .+ y .+ z. \n\n\n\n\n\n","category":"method"},{"location":"internals/#LazyArrays.is_dotcall_nonop-Tuple{Any}","page":"Internals","title":"LazyArrays.is_dotcall_nonop","text":"Check if ex is an expression like f.(x, y, z). \n\n\n\n\n\n","category":"method"},{"location":"internals/#LazyArrays.is_dotcall_op-Tuple{Any}","page":"Internals","title":"LazyArrays.is_dotcall_op","text":"Check if ex is an expression like x .+ y .+ z. \n\n\n\n\n\n","category":"method"}]
}
